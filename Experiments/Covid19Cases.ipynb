{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 90153,
     "status": "ok",
     "timestamp": 1636668876961,
     "user": {
      "displayName": "Alessandro Falcetta",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13950768925623106818"
     },
     "user_tz": -60
    },
    "id": "W4D-K5EL2UGR",
    "outputId": "2a02af39-a3da-4740-f88d-5b34647c4351"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import itertools\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (20,7)\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from math import sqrt\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(device)\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "sys.path.append(module_path) \n",
    "from train_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"Covid-19 Cases\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_experiments = 10\n",
    "num_epochs = 2000\n",
    "learning_rate = 0.001\n",
    "\n",
    "transformation = Identity()  # We do not apply any log, differencing, etc.\n",
    "\n",
    "models = ['PINPOINT_1CONV', 'PINPOINT_2CONV', 'Naive', 'ARIMA', 'ARIMA_PP', 'Prophet']\n",
    "seq_length = 14 #2 * seasonality\n",
    "forecast_horizons = [1, 3, 7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yJyud080hN9s"
   },
   "source": [
    "# Datasets\n",
    "A recap on the time-series we will use in the followings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7g3Rs5qwvKfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function concat at 0x7f5838f45940>\n",
      "Date\n",
      "2021-01-15    16146\n",
      "2021-01-16    16310\n",
      "2021-01-17    12545\n",
      "2021-01-18     8825\n",
      "2021-01-19    10497\n",
      "2021-01-20    13571\n",
      "2021-01-21    14078\n",
      "2021-01-22    13633\n",
      "2021-01-23    13331\n",
      "2021-01-24    11629\n",
      "2021-01-25     8562\n",
      "2021-01-26    10593\n",
      "2021-01-27    15204\n",
      "2021-01-28    14372\n",
      "2021-01-29    13574\n",
      "2021-01-30    12715\n",
      "Freq: D, Name: Daily cases, dtype: int64\n",
      "Date\n",
      "2021-01-31    11252\n",
      "2021-02-01     7925\n",
      "2021-02-02     9660\n",
      "2021-02-03    13189\n",
      "2021-02-04    13659\n",
      "              ...  \n",
      "2021-11-27    12877\n",
      "2021-11-28    12932\n",
      "2021-11-29     7975\n",
      "2021-11-30    12764\n",
      "2021-12-01    15085\n",
      "Freq: D, Name: Daily cases, Length: 305, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# covid daily cases\n",
    "df = pd.read_csv(\"../data/Covid19-italy.csv\", parse_dates=[\"Date\"], index_col=\"Date\")\n",
    "df = df.loc[:pd.Timestamp(\"2021-12-01\"), 'Daily cases']\n",
    "df.index.freq = 'D'\n",
    "entire_ts = df\n",
    "\n",
    "train = entire_ts.loc[:pd.Timestamp(\"2021-01-14\")]\n",
    "validation_length = int(0.05 * len(train))\n",
    "validation = entire_ts.loc[train.index[-1] + entire_ts.index.freq:train.index[-1] + validation_length * entire_ts.index.freq]\n",
    "test = entire_ts.loc[validation.index[-1] + entire_ts.index.freq:]\n",
    "\n",
    "plot_name = \"Covid19\"\n",
    "yaxis_name = \"Cases\"\n",
    "\n",
    "print(train)\n",
    "print(validation)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Square(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    " \n",
    "    def forward(self, t):\n",
    "        return torch.pow(t, 2)\n",
    "\n",
    "class Cube(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    " \n",
    "    def forward(self, t):\n",
    "        return torch.pow(t, 3)\n",
    "    \n",
    "class Printer(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, t):\n",
    "        # print(t)\n",
    "        print(t.shape)\n",
    "        return t\n",
    "\n",
    "\n",
    "class PINPOINT_1CONV(nn.Module):\n",
    "    def __init__(self, input_size, output_horizon):\n",
    "        super(PINPOINT_1CONV, self).__init__()\n",
    "\n",
    "        n_kernels_1 = 32\n",
    "        kernel_size_1 = 3\n",
    "        out_conv_1 = n_kernels_1 * (input_size - kernel_size_1 + 1)\n",
    "\n",
    "        self.main = nn.Sequential(           \n",
    "            nn.Conv1d(in_channels=1, out_channels=n_kernels_1, kernel_size=kernel_size_1),\n",
    "            Square(),\n",
    "            nn.Flatten(),      \n",
    "            \n",
    "            nn.Linear(out_conv_1, int(out_conv_1/2)), #use without avgpool\n",
    "            # nn.Linear(int(out_conv_1/2), output_horizon)   \n",
    "            nn.Linear(int(out_conv_1/2), int(out_conv_1/4)),\n",
    "            nn.Linear(int(out_conv_1/4), output_horizon)   \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.main(x)\n",
    "        return out\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"PINPOINT_1CONV\"\n",
    "\n",
    "    \n",
    "class PINPOINT_2CONV(nn.Module):\n",
    "    def __init__(self, input_size, output_horizon):\n",
    "        super(PINPOINT_2CONV, self).__init__()\n",
    "        \n",
    "        n_kernels_1 = 16\n",
    "        n_kernels_2 = 32\n",
    "        kernel_size_1 = 5\n",
    "        kernel_size_2 = 3\n",
    "        \n",
    "        out_conv_1 = input_size - kernel_size_1 + 1\n",
    "        out_conv_2 = n_kernels_2 * (out_conv_1 - kernel_size_2 + 1)\n",
    "\n",
    "        self.main = nn.Sequential(           \n",
    "            nn.Conv1d(in_channels=1, out_channels=n_kernels_1, kernel_size=kernel_size_1),\n",
    "            Square(),\n",
    "            nn.Conv1d(in_channels=n_kernels_1, out_channels=n_kernels_2, kernel_size=kernel_size_2),\n",
    "            Square(),\n",
    "            nn.Flatten(),      \n",
    "            \n",
    "            nn.Linear(out_conv_2, int(out_conv_2/2)), #use without avgpool\n",
    "            # nn.Linear(int(out_conv_2/4), output_horizon)   \n",
    "            nn.Linear(int(out_conv_2/2), int(out_conv_2/4)),\n",
    "            nn.Linear(int(out_conv_2/4), output_horizon)   \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.main(x)\n",
    "        return out\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"PINPOINT_2CONV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [f\"{m} ({seq_length})\" for m in models if m not in ['Naive', 'ARIMA', 'Prophet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "names.extend(['Naive', 'ARIMA', 'ARIMA_PP', 'Prophet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PINPOINT_1CONV (14)',\n",
       " 'PINPOINT_2CONV (14)',\n",
       " 'ARIMA_PP (14)',\n",
       " 'Naive',\n",
       " 'ARIMA',\n",
       " 'ARIMA_PP',\n",
       " 'Prophet']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(columns = forecast_horizons, \n",
    "                       index = pd.MultiIndex.from_product([names, ['MAE', 'RMSE']], names=[\"Model\", \"Metric\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>3</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">PINPOINT_1CONV (14)</th>\n",
       "      <th>MAE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">PINPOINT_2CONV (14)</th>\n",
       "      <th>MAE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">ARIMA_PP (14)</th>\n",
       "      <th>MAE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Naive</th>\n",
       "      <th>MAE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">ARIMA</th>\n",
       "      <th>MAE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">ARIMA_PP</th>\n",
       "      <th>MAE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Prophet</th>\n",
       "      <th>MAE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              1    3    7\n",
       "Model               Metric               \n",
       "PINPOINT_1CONV (14) MAE     NaN  NaN  NaN\n",
       "                    RMSE    NaN  NaN  NaN\n",
       "PINPOINT_2CONV (14) MAE     NaN  NaN  NaN\n",
       "                    RMSE    NaN  NaN  NaN\n",
       "ARIMA_PP (14)       MAE     NaN  NaN  NaN\n",
       "                    RMSE    NaN  NaN  NaN\n",
       "Naive               MAE     NaN  NaN  NaN\n",
       "                    RMSE    NaN  NaN  NaN\n",
       "ARIMA               MAE     NaN  NaN  NaN\n",
       "                    RMSE    NaN  NaN  NaN\n",
       "ARIMA_PP            MAE     NaN  NaN  NaN\n",
       "                    RMSE    NaN  NaN  NaN\n",
       "Prophet             MAE     NaN  NaN  NaN\n",
       "                    RMSE    NaN  NaN  NaN"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1508185/1865223716.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mforecast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                 \u001b[0m_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m                 \u001b[0m_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0m_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "for forecast_horizon in forecast_horizons:\n",
    "    final_results[forecast_horizon] = {}\n",
    "    \n",
    "    for model_class in models:\n",
    "        if model_class == 'ARIMA':\n",
    "            arima_forecast = np.array([])\n",
    "\n",
    "            _train = train.copy().append(validation.copy())\n",
    "            _train = transformation.apply(_train)\n",
    "            _test = transformation.apply(test.copy())\n",
    "            \n",
    "            arima_model = ARIMA_model()\n",
    "            arima_model.train(_train)\n",
    "            \n",
    "            for i in range(0, int(len(_test) / forecast_horizon) + 1):\n",
    "                arima_forecast = np.append(arima_forecast, arima_model.get_forecast(_train, forecast_horizon))\n",
    "\n",
    "                for j in range(0, forecast_horizon):\n",
    "                    if len(_test) != 0:\n",
    "                        _train[_train.index[-1] + train.index.freq] = _test.iloc[0]\n",
    "                        _test = _test.iloc[1:]\n",
    "            \n",
    "            arima_forecast = transformation.inverse(pd.Series(data=arima_forecast[:len(test)], index=test.index))\n",
    "\n",
    "            final_results[forecast_horizon][f\"forecast_ARIMA\"] = arima_forecast\n",
    "            final_results[forecast_horizon][f\"mae_ARIMA\"] = mean_absolute_error(test, arima_forecast)\n",
    "            final_results[forecast_horizon][f\"rmse_ARIMA\"] = sqrt(mean_squared_error(test, arima_forecast))\n",
    "            metrics.loc[('ARIMA', 'MAE'), forecast_horizon] = mean_absolute_error(test, arima_forecast)\n",
    "            metrics.loc[('ARIMA', 'RMSE'), forecast_horizon] = sqrt(mean_squared_error(test, arima_forecast))\n",
    "        \n",
    "        elif model_class == 'ARIMA_PP':\n",
    "            arima_forecast = np.array([])\n",
    "\n",
    "            _train = train.copy().append(validation.copy())\n",
    "            _train = transformation.apply(_train)\n",
    "            _test = transformation.apply(test.copy())\n",
    "            \n",
    "            arima_model = ARIMA_model()\n",
    "            arima_model.train(_train)\n",
    "            \n",
    "            for i in range(0, int(len(_test) / forecast_horizon) + 1):\n",
    "                arima_forecast = np.append(arima_forecast, arima_model.get_forecast(_train, forecast_horizon, update=False))\n",
    "\n",
    "                for j in range(0, forecast_horizon):\n",
    "                    if len(_test) != 0:\n",
    "                        _train[_train.index[-1] + train.index.freq] = _test.iloc[0]\n",
    "                        _test = _test.iloc[1:]\n",
    "            \n",
    "            arima_forecast = transformation.inverse(pd.Series(data=arima_forecast[:len(test)], index=test.index))\n",
    "\n",
    "            final_results[forecast_horizon][f\"forecast_ARIMA_PP\"] = arima_forecast\n",
    "            final_results[forecast_horizon][f\"mae_ARIMA_PP\"] = mean_absolute_error(test, arima_forecast)\n",
    "            final_results[forecast_horizon][f\"rmse_ARIMA_PP\"] = sqrt(mean_squared_error(test, arima_forecast))\n",
    "            metrics.loc[('ARIMA_PP', 'MAE'), forecast_horizon] = mean_absolute_error(test, arima_forecast)\n",
    "            metrics.loc[('ARIMA_PP', 'RMSE'), forecast_horizon] = sqrt(mean_squared_error(test, arima_forecast))\n",
    "        \n",
    "        elif model_class == 'Prophet':\n",
    "            prophet_forecast = np.array([])\n",
    "            \n",
    "            _train = train.copy().append(validation.copy())\n",
    "            _train = transformation.apply(_train)\n",
    "            _test = transformation.apply(test.copy())\n",
    "\n",
    "            for i in range(0, int(len(_test) / forecast_horizon) + 1):\n",
    "                prophet_forecast = np.append(prophet_forecast, get_prophet_forecast(_train, forecast_horizon).values)\n",
    "\n",
    "                for j in range(0, forecast_horizon):\n",
    "                    if len(_test) != 0:\n",
    "                        _train[_train.index[-1] + train.index.freq] = _test.iloc[0]\n",
    "                        _test = _test.iloc[1:]\n",
    "\n",
    "            prophet_forecast = transformation.inverse(pd.Series(data=prophet_forecast[:len(test)], index=test.index))\n",
    "\n",
    "            final_results[forecast_horizon][f\"forecast_Prophet\"] = prophet_forecast\n",
    "            final_results[forecast_horizon][f\"mae_Prophet\"] = mean_absolute_error(test, prophet_forecast)\n",
    "            final_results[forecast_horizon][f\"rmse_Prophet\"] = sqrt(mean_squared_error(test, prophet_forecast))\n",
    "            metrics.loc[('Prophet', 'MAE'), forecast_horizon] = mean_absolute_error(test, prophet_forecast)\n",
    "            metrics.loc[('Prophet', 'RMSE'), forecast_horizon] = sqrt(mean_squared_error(test, prophet_forecast))\n",
    "        \n",
    "        elif model_class == 'Naive':\n",
    "            naive_forecast = np.array([])\n",
    "            \n",
    "            _train = train.copy().append(validation.copy())\n",
    "            _train = transformation.apply(_train)\n",
    "            _test = transformation.apply(test.copy())\n",
    "            \n",
    "            for i in range(0, int(len(_test) / forecast_horizon) + 1):\n",
    "\n",
    "                for j in range(0, forecast_horizon):\n",
    "                    naive_forecast = np.append(naive_forecast, _train[-1])\n",
    "\n",
    "                for j in range(0, forecast_horizon):\n",
    "                    if len(_test) != 0:\n",
    "                        _train[_train.index[-1] + train.index.freq] = _test.iloc[0]\n",
    "                        _test = _test.iloc[1:]\n",
    "\n",
    "            naive_forecast = transformation.inverse(pd.Series(data=naive_forecast[:len(test)], index=test.index))\n",
    "\n",
    "            final_results[forecast_horizon][f\"forecast_Naive\"] = naive_forecast\n",
    "            final_results[forecast_horizon][f\"mae_Naive\"] = mean_absolute_error(test, naive_forecast)\n",
    "            final_results[forecast_horizon][f\"rmse_Naive\"] = sqrt(mean_squared_error(test, naive_forecast))\n",
    "            metrics.loc[('Naive', 'MAE'), forecast_horizon] = mean_absolute_error(test, naive_forecast)\n",
    "            metrics.loc[('Naive', 'RMSE'), forecast_horizon] = sqrt(mean_squared_error(test, naive_forecast))\n",
    "        \n",
    "        else:\n",
    "            matches = { 'PINPOINT_1CONV': PINPOINT_1CONV, \n",
    "                        'PINPOINT_2CONV': PINPOINT_2CONV}\n",
    "            \n",
    "            model_name = model_class\n",
    "            model_class = matches[model_class]\n",
    "            \n",
    "            forecast_maes = []\n",
    "            forecast_rmses = []\n",
    "\n",
    "            for i in tqdm(range(0, n_experiments)):\n",
    "                forecast = np.array([])\n",
    "\n",
    "                _train = transformation.apply(train.copy()).values\n",
    "                _validation = transformation.apply(validation.copy()).values   \n",
    "                _test = transformation.apply(test.copy()).values\n",
    "\n",
    "                model = model_class(seq_length, forecast_horizon)\n",
    "                model, scaler = train_model(model, _train, _validation, num_epochs, learning_rate, seq_length, forecast_horizon)\n",
    "                torch.save(model, f\"models/{experiment_name}_{forecast_horizon}_{model_name}.pt\")\n",
    "\n",
    "                # Compute the forecast on the testing set\n",
    "                _train = train.copy().append(validation.copy())\n",
    "                _train = transformation.apply(_train)\n",
    "                _test = transformation.apply(test.copy())\n",
    "\n",
    "                for i in range(0, int(len(_test) / forecast_horizon) + 1):\n",
    "                    model.eval()\n",
    "\n",
    "                    inputs = _train.values.reshape(len(_train), 1)\n",
    "\n",
    "                    inputs_normalized = scaler.transform(inputs)\n",
    "                    inputs_normalized = torch.FloatTensor(inputs_normalized[-seq_length:]).to(device)\n",
    "\n",
    "                    predict = model(inputs_normalized.reshape(1, 1, seq_length))\n",
    "                    predict = scaler.inverse_transform(predict.cpu().detach().numpy())\n",
    "                    forecast = np.append(forecast, predict)\n",
    "\n",
    "                    for j in range(0, forecast_horizon):\n",
    "                        if len(_test) > 0:\n",
    "                            _train[_train.index[-1] + train.index.freq] = _test.iloc[0]\n",
    "                            _test = _test.iloc[1:]\n",
    "\n",
    "                forecast = transformation.inverse(pd.Series(data=forecast[:len(test)], index=test.index))\n",
    "\n",
    "                forecast_maes.append(mean_absolute_error(test, forecast))\n",
    "                forecast_rmses.append(sqrt(mean_squared_error(test, forecast)))\n",
    "\n",
    "            final_results[forecast_horizon][f\"forecast_{model}_{seq_length}\"] = forecast\n",
    "            final_results[forecast_horizon][f\"mae_{model}_{seq_length}\"] = np.mean(forecast_maes)\n",
    "            final_results[forecast_horizon][f\"rmse_{model}_{seq_length}\"] = np.mean(forecast_rmses)\n",
    "            metrics.loc[(f\"{model} ({seq_length})\", 'MAE'), forecast_horizon] = np.mean(forecast_maes)\n",
    "            metrics.loc[(f\"{model} ({seq_length})\", 'RMSE'), forecast_horizon] = np.mean(forecast_rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for forecast_horizon in forecast_horizons:\n",
    "    final_result = final_results[forecast_horizon]\n",
    "    \n",
    "    forecasts = {}\n",
    "    maes = {}\n",
    "    rmses = {}\n",
    "    \n",
    "    for model_class in models:\n",
    "        if model_class in ['ARIMA', 'ARIMA_PP', 'Prophet', 'Naive']:\n",
    "            forecasts[f\"{model_class}\"] = final_result[f\"forecast_{model_class}\"]\n",
    "            maes[f\"{model_class}\"] = final_result[f\"mae_{model_class}\"]\n",
    "            rmses[f\"{model_class}\"] = final_result[f\"rmse_{model_class}\"]\n",
    "        else:\n",
    "            forecasts[f\"{model_class}_{seq_length}\"] = final_result[f\"forecast_{model_class}_{seq_length}\"]\n",
    "            maes[f\"{model_class}_{seq_length}\"] = final_result[f\"mae_{model_class}_{seq_length}\"]\n",
    "            rmses[f\"{model_class}_{seq_length}\"] = final_result[f\"rmse_{model_class}_{seq_length}\"]\n",
    "   \n",
    "    print(f\"Forecast horizon: {forecast_horizon}\")\n",
    "    \n",
    "    [print(f\"MAE of model {model_class}: {x}\") for model_class, x in maes.items()]\n",
    "    [print(f\"RMSE of model {model_class}: {x}\") for model_class, x in rmses.items()]\n",
    "    \n",
    "    print(\"Plot and a comparison...\")\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=train.append(validation).index, \n",
    "                             y=train.append(validation),\n",
    "                             name='Starting train'))\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=test.index, \n",
    "                             y=test,\n",
    "                             name='Test'))\n",
    "\n",
    "    [fig.add_trace(go.Scatter(x=forecast.index, \n",
    "                              y=forecast,\n",
    "                              name=f'Predicted points ({model_class})')) for model_class, forecast in forecasts.items()]\n",
    "\n",
    "    fig.update_layout(title_text = plot_name)\n",
    "    fig.update_xaxes(title_text = \"Date\")\n",
    "    fig.update_yaxes(title_text = yaxis_name)\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in metrics.columns:\n",
    "    print(metrics.loc[metrics.loc[:, column] == min(metrics.loc[:, column])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_csv = metrics.loc[([f\"PINPOINT_1CONV ({seq_length})\", f\"PINPOINT_2CONV ({seq_length})\", \n",
    "              'Prophet', 'ARIMA', 'ARIMA_PP', 'Naive']), :].astype(\"float64\").round(2)\n",
    "\n",
    "final_csv.columns = [f\"{experiment_name}_{x}\" for x in final_csv.columns]\n",
    "final_csv = final_csv.rename(index={f\"PINPOINT_1CONV ({seq_length})\": 'PINPOINT_1CONV', \n",
    "                                    f\"PINPOINT_2CONV ({seq_length})\": 'PINPOINT_2CONV'})\n",
    "\n",
    "final_csv.to_csv(f\"results/{experiment_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copia di TS_Exercises2_Planned.ipynb",
   "provenance": [
    {
     "file_id": "1W1_DAqrdw9AQrIWwZLPsGMRA8xDBAjKM",
     "timestamp": 1636703056169
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "PINPOINT",
   "language": "python",
   "name": "pinpoint"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
