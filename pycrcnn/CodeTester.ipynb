{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 90153,
     "status": "ok",
     "timestamp": 1636668876961,
     "user": {
      "displayName": "Alessandro Falcetta",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13950768925623106818"
     },
     "user_tz": -60
    },
    "id": "W4D-K5EL2UGR",
    "outputId": "2a02af39-a3da-4740-f88d-5b34647c4351"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from memory_profiler import profile\n",
    "\n",
    "from Pyfhel import Pyfhel, PyPtxt, PyCtxt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "\n",
    "working_directory = \"/home/falcetta/PINPOINT_Secret\"\n",
    "\n",
    "device = \"cpu\"\n",
    "module_path = os.path.abspath(working_directory)\n",
    "sys.path.append(module_path) \n",
    "\n",
    "from pycrcnn.net_builder.encoded_net_builder_ts import build_from_pytorch\n",
    "from pycrcnn.crypto.crypto import encrypt_matrix, decrypt_matrix\n",
    "from train_utils import *\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HE = Pyfhel()    \n",
    "# HE.contextGen(p=6514233, m=8192, intDigits=16, fracDigits=32) \n",
    "# HE.keyGen()\n",
    "# HE.relinKeyGen(30, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = 0.5\n",
    "\n",
    "# print(\"First conv\")\n",
    "# a = (a * 0.1) - 0.3\n",
    "# print(a)\n",
    "\n",
    "# print(\"First square\")\n",
    "# a = a * a\n",
    "# print(a)\n",
    "\n",
    "# print(\"Second conv\")\n",
    "# a = (a * 0.2) - 0.1\n",
    "# print(a)\n",
    "\n",
    "# print(\"Second square\")\n",
    "# a = a * a\n",
    "# print(a)\n",
    "\n",
    "# print(\"First linear\")\n",
    "# a = (a * 0.1) + (a * 0.05) + (a * 0.3) - 0.1\n",
    "# print(a)\n",
    "\n",
    "# print(\"Second linear\")\n",
    "# a = (a * -0.2) + (a * 0.1) + (a * 0.1) - 0.4\n",
    "# print(a)\n",
    "\n",
    "# print(\"Third linear\")\n",
    "# a = (a * 0.3) + (a * -0.2) + (a * 0.3) + 0.2\n",
    "# print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = 0.51951235\n",
    "# enc_a = HE.encryptFrac(a)\n",
    "\n",
    "# print(\"First conv\")\n",
    "# enc_a = (enc_a * HE.encodeFrac(0.1)) - HE.encodeFrac(0.3)\n",
    "# print(HE.decryptFrac(enc_a))\n",
    "\n",
    "# print(\"First square\")\n",
    "# enc_a = HE.power(enc_a, 2)\n",
    "# print(HE.decryptFrac(enc_a))\n",
    "\n",
    "# print(\"Second conv\")\n",
    "# enc_a = (enc_a * HE.encodeFrac(0.2)) - HE.encodeFrac(0.1)\n",
    "# print(HE.decryptFrac(enc_a))\n",
    "\n",
    "# print(\"Second square\")\n",
    "# enc_a = HE.power(enc_a, 2)\n",
    "# print(HE.decryptFrac(enc_a))\n",
    "\n",
    "# print(\"First linear\")\n",
    "# enc_a = (enc_a * HE.encodeFrac(0.1)) + (enc_a * HE.encodeFrac(0.05)) + (enc_a * HE.encodeFrac(0.3)) + HE.encodeFrac(0.1)\n",
    "# print(HE.decryptFrac(enc_a))\n",
    "\n",
    "# print(\"Second linear\")\n",
    "# enc_a = (enc_a * HE.encodeFrac(-0.2)) + (enc_a * HE.encodeFrac(0.1)) + (enc_a * HE.encodeFrac(0.1)) + HE.encodeFrac(-0.4)\n",
    "# print(HE.decryptFrac(enc_a))\n",
    "\n",
    "# print(\"Third linear\")\n",
    "# enc_a = (enc_a * HE.encodeFrac(0.3)) + (enc_a * HE.encodeFrac(-0.2)) + (enc_a * HE.encodeFrac(0.3)) + HE.encodeFrac(0.2)\n",
    "# print(HE.decryptFrac(enc_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Square(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    " \n",
    "    def forward(self, t):\n",
    "        return torch.pow(t, 2)\n",
    "\n",
    "class Cube(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    " \n",
    "    def forward(self, t):\n",
    "        return torch.pow(t, 3)\n",
    "    \n",
    "class Printer(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, t):\n",
    "        # print(t)\n",
    "        print(t.shape)\n",
    "        return t\n",
    "\n",
    "\n",
    "class PINPOINT_1CONV(nn.Module):\n",
    "    def __init__(self, input_size, output_horizon):\n",
    "        super(PINPOINT_1CONV, self).__init__()\n",
    "\n",
    "        n_kernels_1 = 32\n",
    "        kernel_size_1 = 3\n",
    "        out_conv_1 = n_kernels_1 * (input_size - kernel_size_1 + 1)\n",
    "\n",
    "        self.main = nn.Sequential(           \n",
    "            nn.Conv1d(in_channels=1, out_channels=n_kernels_1, kernel_size=kernel_size_1),\n",
    "            Square(),\n",
    "            nn.Flatten(),      \n",
    "            \n",
    "            nn.Linear(out_conv_1, int(out_conv_1/2)), #use without avgpool\n",
    "            # nn.Linear(int(out_conv_1/2), output_horizon)   \n",
    "            nn.Linear(int(out_conv_1/2), int(out_conv_1/4)),\n",
    "            nn.Linear(int(out_conv_1/4), output_horizon)   \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        for l in self.main:\n",
    "            try:\n",
    "                print(x[0][0][0])\n",
    "            except Exception:\n",
    "                print(x[0][0])\n",
    "            x = l(x)\n",
    "        print(x[0][0])\n",
    "        return x\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"PINPOINT_1CONV\"\n",
    "\n",
    "    \n",
    "class PINPOINT_2CONV(nn.Module):\n",
    "    def __init__(self, input_size, output_horizon):\n",
    "        super(PINPOINT_2CONV, self).__init__()\n",
    "        \n",
    "        n_kernels_1 = 16\n",
    "        n_kernels_2 = 32\n",
    "        kernel_size_1 = 5\n",
    "        kernel_size_2 = 3\n",
    "        \n",
    "        out_conv_1 = input_size - kernel_size_1 + 1\n",
    "        out_conv_2 = n_kernels_2 * (out_conv_1 - kernel_size_2 + 1)\n",
    "\n",
    "        self.main = nn.Sequential(           \n",
    "            nn.Conv1d(in_channels=1, out_channels=n_kernels_1, kernel_size=kernel_size_1),\n",
    "            Square(),\n",
    "            nn.Conv1d(in_channels=n_kernels_1, out_channels=n_kernels_2, kernel_size=kernel_size_2),\n",
    "            Square(),\n",
    "            nn.Flatten(),      \n",
    "            \n",
    "            nn.Linear(out_conv_2, int(out_conv_2/2)), #use without avgpool\n",
    "            # nn.Linear(int(out_conv_2/4), output_horizon)   \n",
    "            nn.Linear(int(out_conv_2/2), int(out_conv_2/4)),\n",
    "            nn.Linear(int(out_conv_2/4), output_horizon)   \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x)\n",
    "        for l in self.main:\n",
    "            try:\n",
    "                print(x)\n",
    "            except Exception:\n",
    "                print(x[0][0])\n",
    "            x = l(x)\n",
    "        print(x[0][0])\n",
    "        return x\n",
    "    \n",
    "        # out = self.main(x)\n",
    "        # return out\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"PINPOINT_2CONV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"Milk\"\n",
    "seq_length = 12\n",
    "forecast_horizon = 6\n",
    "model_class = \"PINPOINT_2CONV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(f\"{working_directory}/Experiments/models/{experiment_name}_{forecast_horizon}_{model_class}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PINPOINT_2CONV(\n",
       "  (main): Sequential(\n",
       "    (0): Conv1d(1, 16, kernel_size=(5,), stride=(1,))\n",
       "    (1): Square()\n",
       "    (2): Conv1d(16, 32, kernel_size=(3,), stride=(1,))\n",
       "    (3): Square()\n",
       "    (4): Flatten(start_dim=1, end_dim=-1)\n",
       "    (5): Linear(in_features=192, out_features=96, bias=True)\n",
       "    (6): Linear(in_features=96, out_features=48, bias=True)\n",
       "    (7): Linear(in_features=48, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month\n",
      "1962-01-01    589\n",
      "1962-02-01    561\n",
      "1962-03-01    640\n",
      "1962-04-01    656\n",
      "1962-05-01    727\n",
      "             ... \n",
      "1974-04-01    902\n",
      "1974-05-01    969\n",
      "1974-06-01    947\n",
      "1974-07-01    908\n",
      "1974-08-01    867\n",
      "Freq: MS, Name: Production, Length: 152, dtype: int64\n",
      "Month\n",
      "1974-09-01    815\n",
      "1974-10-01    812\n",
      "1974-11-01    773\n",
      "1974-12-01    813\n",
      "1975-01-01    834\n",
      "1975-02-01    782\n",
      "1975-03-01    892\n",
      "1975-04-01    903\n",
      "1975-05-01    966\n",
      "1975-06-01    937\n",
      "1975-07-01    896\n",
      "1975-08-01    858\n",
      "1975-09-01    817\n",
      "1975-10-01    827\n",
      "1975-11-01    797\n",
      "1975-12-01    843\n",
      "Freq: MS, Name: Production, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "milk_production = milk_production = pd.read_csv(f\"{working_directory}/data/monthly-milk-production.csv\", parse_dates=[\"Month\"], index_col=\"Month\")\n",
    "milk_production = milk_production.loc[:, 'Production']\n",
    "milk_production.index.freq = 'MS'\n",
    "entire_ts = milk_production\n",
    "train = milk_production.loc[:pd.Timestamp(\"1974-01-01\")]\n",
    "validation_length = int(0.05 * len(train))\n",
    "validation = entire_ts.loc[train.index[-1] + entire_ts.index.freq:train.index[-1] + validation_length * entire_ts.index.freq]\n",
    "test = entire_ts.loc[validation.index[-1] + entire_ts.index.freq:]\n",
    "plot_name = \"Monthly milk production\"\n",
    "yaxis_name = \"Production\"\n",
    "\n",
    "train = train.append(validation)\n",
    "\n",
    "print(train)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1106,  0.1442, -0.0048,  0.1971,  0.3221,  0.0817,  0.6154,\n",
      "           0.6779,  1.0000,  0.8942,  0.7067,  0.5096]]], device='cuda:0')\n",
      "tensor([[[ 0.1106,  0.1442, -0.0048,  0.1971,  0.3221,  0.0817,  0.6154,\n",
      "           0.6779,  1.0000,  0.8942,  0.7067,  0.5096]]], device='cuda:0')\n",
      "tensor([[[-0.1528, -0.1989,  0.1217, -0.0887,  0.2874,  0.0773,  0.1500,\n",
      "           0.0182],\n",
      "         [ 0.2772,  0.4068,  0.0712,  0.2011,  0.1136,  0.0255,  0.0407,\n",
      "          -0.0209],\n",
      "         [-0.0813, -0.0741, -0.0850,  0.1376,  0.1174,  0.4252,  0.5376,\n",
      "           0.6240],\n",
      "         [ 0.3105,  0.3048,  0.4863,  0.5388,  0.8507,  0.8372,  0.9536,\n",
      "           0.8414],\n",
      "         [ 0.6594,  0.5616,  0.6862,  0.8686,  0.9524,  0.9204,  1.0105,\n",
      "           0.9946],\n",
      "         [ 0.4080,  0.4732,  0.5711,  0.3409,  0.5546,  0.4636,  0.3316,\n",
      "           0.1734],\n",
      "         [-0.3063, -0.0998, -0.2748, -0.4743, -0.4366, -0.3012, -0.3969,\n",
      "          -0.4545],\n",
      "         [ 0.6177,  0.5862,  0.8820,  0.8152,  1.0037,  1.2818,  1.0794,\n",
      "           0.9966],\n",
      "         [-0.1898, -0.3233, -0.2825, -0.2274, -0.3665, -0.5276, -0.4395,\n",
      "          -0.3338],\n",
      "         [ 0.4722,  0.4235,  0.7779,  0.8197,  1.0551,  1.4585,  1.2469,\n",
      "           1.1488],\n",
      "         [-0.0203,  0.0562, -0.0045,  0.1166,  0.3143,  0.2529,  0.3595,\n",
      "           0.2336],\n",
      "         [-0.3861, -0.4648, -0.1876, -0.2821, -0.0828, -0.1102, -0.1083,\n",
      "          -0.1553],\n",
      "         [-0.5883, -0.4187, -0.5972, -0.7829, -0.6365, -0.8219, -0.4529,\n",
      "          -0.4160],\n",
      "         [-0.3501, -0.2603, -0.3645, -0.5205, -0.5242, -0.6204, -0.8819,\n",
      "          -1.0276],\n",
      "         [ 0.1501,  0.0799,  0.2634,  0.1864,  0.2153,  0.2657,  0.0352,\n",
      "          -0.0273],\n",
      "         [ 0.0923,  0.1163,  0.0157,  0.2947,  0.3738,  0.2961,  0.0028,\n",
      "          -0.2842]]], device='cuda:0', grad_fn=<ConvolutionBackward0>)\n",
      "tensor([[[2.3334e-02, 3.9561e-02, 1.4818e-02, 7.8720e-03, 8.2605e-02,\n",
      "          5.9782e-03, 2.2498e-02, 3.3153e-04],\n",
      "         [7.6842e-02, 1.6545e-01, 5.0634e-03, 4.0451e-02, 1.2896e-02,\n",
      "          6.5069e-04, 1.6586e-03, 4.3529e-04],\n",
      "         [6.6105e-03, 5.4897e-03, 7.2205e-03, 1.8943e-02, 1.3776e-02,\n",
      "          1.8078e-01, 2.8905e-01, 3.8932e-01],\n",
      "         [9.6391e-02, 9.2930e-02, 2.3649e-01, 2.9028e-01, 7.2373e-01,\n",
      "          7.0087e-01, 9.0937e-01, 7.0793e-01],\n",
      "         [4.3478e-01, 3.1542e-01, 4.7091e-01, 7.5451e-01, 9.0709e-01,\n",
      "          8.4713e-01, 1.0210e+00, 9.8930e-01],\n",
      "         [1.6650e-01, 2.2388e-01, 3.2616e-01, 1.1624e-01, 3.0756e-01,\n",
      "          2.1490e-01, 1.0993e-01, 3.0078e-02],\n",
      "         [9.3844e-02, 9.9589e-03, 7.5491e-02, 2.2496e-01, 1.9062e-01,\n",
      "          9.0709e-02, 1.5756e-01, 2.0653e-01],\n",
      "         [3.8159e-01, 3.4365e-01, 7.7793e-01, 6.6460e-01, 1.0073e+00,\n",
      "          1.6430e+00, 1.1651e+00, 9.9314e-01],\n",
      "         [3.6011e-02, 1.0451e-01, 7.9804e-02, 5.1709e-02, 1.3435e-01,\n",
      "          2.7841e-01, 1.9319e-01, 1.1142e-01],\n",
      "         [2.2299e-01, 1.7934e-01, 6.0507e-01, 6.7186e-01, 1.1132e+00,\n",
      "          2.1273e+00, 1.5547e+00, 1.3198e+00],\n",
      "         [4.1141e-04, 3.1579e-03, 2.0506e-05, 1.3596e-02, 9.8771e-02,\n",
      "          6.3934e-02, 1.2927e-01, 5.4574e-02],\n",
      "         [1.4908e-01, 2.1607e-01, 3.5185e-02, 7.9580e-02, 6.8516e-03,\n",
      "          1.2134e-02, 1.1738e-02, 2.4128e-02],\n",
      "         [3.4604e-01, 1.7533e-01, 3.5668e-01, 6.1286e-01, 4.0516e-01,\n",
      "          6.7555e-01, 2.0510e-01, 1.7307e-01],\n",
      "         [1.2260e-01, 6.7732e-02, 1.3283e-01, 2.7092e-01, 2.7480e-01,\n",
      "          3.8484e-01, 7.7774e-01, 1.0559e+00],\n",
      "         [2.2544e-02, 6.3820e-03, 6.9383e-02, 3.4742e-02, 4.6358e-02,\n",
      "          7.0588e-02, 1.2422e-03, 7.4279e-04],\n",
      "         [8.5275e-03, 1.3533e-02, 2.4601e-04, 8.6830e-02, 1.3975e-01,\n",
      "          8.7669e-02, 8.0638e-06, 8.0772e-02]]], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor([[[-0.0555, -0.1815, -0.0286, -0.1993, -0.2317,  0.1662],\n",
      "         [-0.0929,  0.0405,  0.2272,  0.2538,  0.3314,  0.3574],\n",
      "         [ 0.0821,  0.0696, -0.1254, -0.2248, -0.3771, -0.5120],\n",
      "         [ 0.0897,  0.3011,  0.2157,  0.2273,  0.4024,  0.0160],\n",
      "         [-0.2348, -0.1891, -0.4143, -0.6445, -0.6725, -0.5186],\n",
      "         [-0.3115, -0.5124, -0.4141, -0.7543, -0.5564, -0.0624],\n",
      "         [-0.0063,  0.0782,  0.3131,  0.4792,  0.1697,  0.0019],\n",
      "         [ 0.3883,  0.2814,  0.2302,  0.1929,  0.0860,  0.0547],\n",
      "         [-0.0103, -0.0866, -0.0845, -0.2272, -0.2836, -0.3475],\n",
      "         [ 0.0695,  0.0418,  0.1527,  0.2044,  0.3055,  0.3340],\n",
      "         [ 0.0618,  0.1142,  0.2249,  0.0717,  0.5279,  0.5969],\n",
      "         [-0.3508, -0.4079, -0.4973, -0.6754, -0.5836, -0.8095],\n",
      "         [ 0.0817,  0.1176,  0.2156,  0.2848,  0.4135,  0.2973],\n",
      "         [ 0.3706,  0.4031,  0.6446,  0.6086,  0.7867,  0.9804],\n",
      "         [ 0.2638,  0.3478,  0.3275,  0.0529,  0.1568, -0.1177],\n",
      "         [-0.2128, -0.2273, -0.3139, -0.4620, -0.5227, -0.4389],\n",
      "         [-0.0457, -0.1374, -0.4051, -0.3741, -0.2615, -0.3413],\n",
      "         [ 0.1800,  0.1077,  0.2179,  0.2228,  0.2831,  0.4906],\n",
      "         [-0.0143, -0.0962, -0.2825, -0.4606, -0.5511, -0.6809],\n",
      "         [ 0.1298,  0.2209,  0.3020,  0.6080,  0.5766,  0.6162],\n",
      "         [-0.2166, -0.3369, -0.3299, -0.5574, -0.3327, -0.1353],\n",
      "         [ 0.2915,  0.3317,  0.4396,  0.3631,  0.2712,  0.2904],\n",
      "         [-0.2849, -0.2091, -0.1602, -0.4066, -0.1454, -0.0553],\n",
      "         [-0.0399,  0.0538,  0.1728,  0.2327,  0.3802,  0.2479],\n",
      "         [-0.0152,  0.0243,  0.2531,  0.4538,  0.4256,  0.6544],\n",
      "         [-0.0215,  0.0513,  0.1730,  0.4894,  0.3611,  0.4776],\n",
      "         [-0.0159, -0.0453, -0.2384, -0.2825, -0.6129, -0.4399],\n",
      "         [ 0.0926,  0.1647,  0.2173,  0.4573,  0.4565,  0.2617],\n",
      "         [-0.2050, -0.2055, -0.2249, -0.2205, -0.2650, -0.0507],\n",
      "         [ 0.6030,  0.7945,  0.7704,  1.0514,  0.9585,  0.9617],\n",
      "         [-0.0549,  0.1166,  0.0229,  0.2127,  0.3548, -0.2575],\n",
      "         [ 0.2412,  0.3511,  0.2874,  0.3208,  0.2355,  0.3500]]],\n",
      "       device='cuda:0', grad_fn=<ConvolutionBackward0>)\n",
      "tensor([[[3.0858e-03, 3.2960e-02, 8.1880e-04, 3.9729e-02, 5.3663e-02,\n",
      "          2.7610e-02],\n",
      "         [8.6257e-03, 1.6373e-03, 5.1599e-02, 6.4433e-02, 1.0980e-01,\n",
      "          1.2772e-01],\n",
      "         [6.7352e-03, 4.8413e-03, 1.5727e-02, 5.0546e-02, 1.4220e-01,\n",
      "          2.6211e-01],\n",
      "         [8.0483e-03, 9.0659e-02, 4.6509e-02, 5.1655e-02, 1.6192e-01,\n",
      "          2.5753e-04],\n",
      "         [5.5144e-02, 3.5740e-02, 1.7167e-01, 4.1532e-01, 4.5225e-01,\n",
      "          2.6896e-01],\n",
      "         [9.7013e-02, 2.6254e-01, 1.7147e-01, 5.6904e-01, 3.0957e-01,\n",
      "          3.8893e-03],\n",
      "         [3.9824e-05, 6.1189e-03, 9.8045e-02, 2.2959e-01, 2.8784e-02,\n",
      "          3.6983e-06],\n",
      "         [1.5079e-01, 7.9171e-02, 5.2986e-02, 3.7210e-02, 7.3943e-03,\n",
      "          2.9973e-03],\n",
      "         [1.0536e-04, 7.4941e-03, 7.1397e-03, 5.1633e-02, 8.0443e-02,\n",
      "          1.2076e-01],\n",
      "         [4.8273e-03, 1.7440e-03, 2.3314e-02, 4.1765e-02, 9.3341e-02,\n",
      "          1.1157e-01],\n",
      "         [3.8172e-03, 1.3038e-02, 5.0592e-02, 5.1441e-03, 2.7866e-01,\n",
      "          3.5632e-01],\n",
      "         [1.2308e-01, 1.6640e-01, 2.4730e-01, 4.5618e-01, 3.4055e-01,\n",
      "          6.5529e-01],\n",
      "         [6.6754e-03, 1.3837e-02, 4.6487e-02, 8.1136e-02, 1.7094e-01,\n",
      "          8.8378e-02],\n",
      "         [1.3734e-01, 1.6251e-01, 4.1555e-01, 3.7034e-01, 6.1896e-01,\n",
      "          9.6115e-01],\n",
      "         [6.9576e-02, 1.2096e-01, 1.0726e-01, 2.7973e-03, 2.4585e-02,\n",
      "          1.3848e-02],\n",
      "         [4.5304e-02, 5.1682e-02, 9.8551e-02, 2.1342e-01, 2.7322e-01,\n",
      "          1.9260e-01],\n",
      "         [2.0867e-03, 1.8886e-02, 1.6407e-01, 1.3993e-01, 6.8362e-02,\n",
      "          1.1651e-01],\n",
      "         [3.2385e-02, 1.1608e-02, 4.7472e-02, 4.9658e-02, 8.0144e-02,\n",
      "          2.4064e-01],\n",
      "         [2.0340e-04, 9.2495e-03, 7.9826e-02, 2.1217e-01, 3.0375e-01,\n",
      "          4.6364e-01],\n",
      "         [1.6859e-02, 4.8798e-02, 9.1205e-02, 3.6962e-01, 3.3251e-01,\n",
      "          3.7976e-01],\n",
      "         [4.6897e-02, 1.1352e-01, 1.0883e-01, 3.1069e-01, 1.1066e-01,\n",
      "          1.8308e-02],\n",
      "         [8.4966e-02, 1.1001e-01, 1.9322e-01, 1.3188e-01, 7.3538e-02,\n",
      "          8.4336e-02],\n",
      "         [8.1148e-02, 4.3718e-02, 2.5675e-02, 1.6536e-01, 2.1136e-02,\n",
      "          3.0612e-03],\n",
      "         [1.5940e-03, 2.8994e-03, 2.9857e-02, 5.4148e-02, 1.4455e-01,\n",
      "          6.1439e-02],\n",
      "         [2.3100e-04, 5.9045e-04, 6.4076e-02, 2.0590e-01, 1.8117e-01,\n",
      "          4.2819e-01],\n",
      "         [4.6025e-04, 2.6340e-03, 2.9939e-02, 2.3953e-01, 1.3041e-01,\n",
      "          2.2813e-01],\n",
      "         [2.5287e-04, 2.0535e-03, 5.6838e-02, 7.9792e-02, 3.7568e-01,\n",
      "          1.9348e-01],\n",
      "         [8.5723e-03, 2.7132e-02, 4.7206e-02, 2.0915e-01, 2.0836e-01,\n",
      "          6.8489e-02],\n",
      "         [4.2009e-02, 4.2217e-02, 5.0601e-02, 4.8633e-02, 7.0203e-02,\n",
      "          2.5689e-03],\n",
      "         [3.6367e-01, 6.3121e-01, 5.9348e-01, 1.1055e+00, 9.1879e-01,\n",
      "          9.2496e-01],\n",
      "         [3.0130e-03, 1.3593e-02, 5.2496e-04, 4.5247e-02, 1.2589e-01,\n",
      "          6.6316e-02],\n",
      "         [5.8180e-02, 1.2327e-01, 8.2625e-02, 1.0290e-01, 5.5471e-02,\n",
      "          1.2248e-01]]], device='cuda:0', grad_fn=<PowBackward0>)\n",
      "tensor([[3.0858e-03, 3.2960e-02, 8.1880e-04, 3.9729e-02, 5.3663e-02, 2.7610e-02,\n",
      "         8.6257e-03, 1.6373e-03, 5.1599e-02, 6.4433e-02, 1.0980e-01, 1.2772e-01,\n",
      "         6.7352e-03, 4.8413e-03, 1.5727e-02, 5.0546e-02, 1.4220e-01, 2.6211e-01,\n",
      "         8.0483e-03, 9.0659e-02, 4.6509e-02, 5.1655e-02, 1.6192e-01, 2.5753e-04,\n",
      "         5.5144e-02, 3.5740e-02, 1.7167e-01, 4.1532e-01, 4.5225e-01, 2.6896e-01,\n",
      "         9.7013e-02, 2.6254e-01, 1.7147e-01, 5.6904e-01, 3.0957e-01, 3.8893e-03,\n",
      "         3.9824e-05, 6.1189e-03, 9.8045e-02, 2.2959e-01, 2.8784e-02, 3.6983e-06,\n",
      "         1.5079e-01, 7.9171e-02, 5.2986e-02, 3.7210e-02, 7.3943e-03, 2.9973e-03,\n",
      "         1.0536e-04, 7.4941e-03, 7.1397e-03, 5.1633e-02, 8.0443e-02, 1.2076e-01,\n",
      "         4.8273e-03, 1.7440e-03, 2.3314e-02, 4.1765e-02, 9.3341e-02, 1.1157e-01,\n",
      "         3.8172e-03, 1.3038e-02, 5.0592e-02, 5.1441e-03, 2.7866e-01, 3.5632e-01,\n",
      "         1.2308e-01, 1.6640e-01, 2.4730e-01, 4.5618e-01, 3.4055e-01, 6.5529e-01,\n",
      "         6.6754e-03, 1.3837e-02, 4.6487e-02, 8.1136e-02, 1.7094e-01, 8.8378e-02,\n",
      "         1.3734e-01, 1.6251e-01, 4.1555e-01, 3.7034e-01, 6.1896e-01, 9.6115e-01,\n",
      "         6.9576e-02, 1.2096e-01, 1.0726e-01, 2.7973e-03, 2.4585e-02, 1.3848e-02,\n",
      "         4.5304e-02, 5.1682e-02, 9.8551e-02, 2.1342e-01, 2.7322e-01, 1.9260e-01,\n",
      "         2.0867e-03, 1.8886e-02, 1.6407e-01, 1.3993e-01, 6.8362e-02, 1.1651e-01,\n",
      "         3.2385e-02, 1.1608e-02, 4.7472e-02, 4.9658e-02, 8.0144e-02, 2.4064e-01,\n",
      "         2.0340e-04, 9.2495e-03, 7.9826e-02, 2.1217e-01, 3.0375e-01, 4.6364e-01,\n",
      "         1.6859e-02, 4.8798e-02, 9.1205e-02, 3.6962e-01, 3.3251e-01, 3.7976e-01,\n",
      "         4.6897e-02, 1.1352e-01, 1.0883e-01, 3.1069e-01, 1.1066e-01, 1.8308e-02,\n",
      "         8.4966e-02, 1.1001e-01, 1.9322e-01, 1.3188e-01, 7.3538e-02, 8.4336e-02,\n",
      "         8.1148e-02, 4.3718e-02, 2.5675e-02, 1.6536e-01, 2.1136e-02, 3.0612e-03,\n",
      "         1.5940e-03, 2.8994e-03, 2.9857e-02, 5.4148e-02, 1.4455e-01, 6.1439e-02,\n",
      "         2.3100e-04, 5.9045e-04, 6.4076e-02, 2.0590e-01, 1.8117e-01, 4.2819e-01,\n",
      "         4.6025e-04, 2.6340e-03, 2.9939e-02, 2.3953e-01, 1.3041e-01, 2.2813e-01,\n",
      "         2.5287e-04, 2.0535e-03, 5.6838e-02, 7.9792e-02, 3.7568e-01, 1.9348e-01,\n",
      "         8.5723e-03, 2.7132e-02, 4.7206e-02, 2.0915e-01, 2.0836e-01, 6.8489e-02,\n",
      "         4.2009e-02, 4.2217e-02, 5.0601e-02, 4.8633e-02, 7.0203e-02, 2.5689e-03,\n",
      "         3.6367e-01, 6.3121e-01, 5.9348e-01, 1.1055e+00, 9.1879e-01, 9.2496e-01,\n",
      "         3.0130e-03, 1.3593e-02, 5.2496e-04, 4.5247e-02, 1.2589e-01, 6.6316e-02,\n",
      "         5.8180e-02, 1.2327e-01, 8.2625e-02, 1.0290e-01, 5.5471e-02, 1.2248e-01]],\n",
      "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "tensor([[ 0.0583,  0.1100,  0.0318, -0.0787,  0.0482, -0.0372,  0.0496,  0.0610,\n",
      "          0.0624,  0.0605, -0.1412, -0.0921, -0.1642,  0.1643, -0.2354, -0.0770,\n",
      "          0.2642, -0.0759, -0.0703,  0.0423, -0.1780, -0.0225, -0.0594,  0.0556,\n",
      "          0.0269, -0.0587,  0.1704,  0.0538,  0.0525,  0.0049,  0.1668,  0.1658,\n",
      "          0.2358,  0.0540, -0.1297, -0.0051, -0.1747, -0.0439, -0.0821,  0.0715,\n",
      "          0.1560, -0.0810,  0.0773, -0.1504, -0.1020, -0.0869, -0.1746, -0.0503,\n",
      "          0.1000, -0.1182,  0.0716, -0.0928, -0.1330, -0.1182, -0.0389, -0.1126,\n",
      "          0.0474,  0.0320,  0.0766, -0.0921, -0.0911, -0.0402,  0.1032, -0.1247,\n",
      "          0.0608,  0.0355, -0.0890,  0.0616,  0.0913,  0.3176, -0.0216, -0.2003,\n",
      "          0.0679,  0.0917, -0.0250, -0.1605, -0.0051,  0.0256,  0.0598, -0.1033,\n",
      "         -0.1735,  0.0054, -0.0894,  0.1314, -0.1498,  0.1491, -0.2084, -0.1259,\n",
      "         -0.0959, -0.0742,  0.0580, -0.0155,  0.0957, -0.1536,  0.1566, -0.0295]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.0054, -0.1247,  0.0824, -0.2803,  0.1171, -0.0059, -0.1131, -0.1150,\n",
      "         -0.1781, -0.0074,  0.2057,  0.1017, -0.0777, -0.2465,  0.0556, -0.0686,\n",
      "          0.2087,  0.0510, -0.1576,  0.0293, -0.0229, -0.1217, -0.0614,  0.0671,\n",
      "          0.3498, -0.1491,  0.0643, -0.1478, -0.1186, -0.2168, -0.1375, -0.2063,\n",
      "          0.1670,  0.1581, -0.2613, -0.3567,  0.0146,  0.1395,  0.0173,  0.0593,\n",
      "         -0.0098,  0.1987, -0.1792, -0.0346, -0.0190,  0.0771, -0.1461, -0.1995]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor(0.2454, device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "expected_output = []\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "_ = scaler.fit_transform(train.values.reshape(-1, 1))\n",
    "\n",
    "_train = train.copy()\n",
    "_test = test.copy()\n",
    "\n",
    "forecast = np.array([])\n",
    "\n",
    "for i in range(0, int(len(_test) / forecast_horizon) + 1):\n",
    "    if i > 0: \n",
    "        break\n",
    "    model.eval()\n",
    "\n",
    "    inputs = _train.values.reshape(len(_train), 1)\n",
    "\n",
    "    inputs_normalized = scaler.transform(inputs)\n",
    "    inputs_normalized = torch.FloatTensor(inputs_normalized[-seq_length:]).to(device)\n",
    "\n",
    "    predict = model(inputs_normalized.reshape(1, 1, seq_length))\n",
    "    predict = scaler.inverse_transform(predict.cpu().detach().numpy())\n",
    "    forecast = np.append(forecast, predict)\n",
    "\n",
    "    for j in range(0, forecast_horizon):\n",
    "        if len(_test) > 0:\n",
    "            _train[_train.index[-1] + train.index.freq] = _test.iloc[0]\n",
    "            _test = _test.iloc[1:]\n",
    "\n",
    "# expected_output = pd.Series(data=forecast[:len(test)], index=test.index)\n",
    "expected_output = pd.Series(data=forecast[:len(test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    812.044067\n",
       "1    823.361755\n",
       "2    764.408569\n",
       "3    813.593750\n",
       "4    839.368958\n",
       "5    790.813354\n",
       "dtype: float64"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(experiment_name)\n",
    "# print(f\"MAE of model {model}, forecast horizon: {forecast_horizon}: {round(mean_absolute_error(test, expected_output), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalLayer:\n",
    "    def __init__(self, weights, stride=(1, 1), padding=(0, 0), bias=None):\n",
    "        self.weights = weights\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.bias = bias\n",
    "        if bias is not None:\n",
    "            self.bias = bias\n",
    "\n",
    "    def __call__(self, t):\n",
    "        # t = apply_padding(t, self.padding)\n",
    "        result = np.array([[np.sum([convolute1d(ts_layer, filter_layer, self.stride)\n",
    "                                    for ts_layer, filter_layer in zip(_ts, _filter)], axis=0)\n",
    "                             for _filter in self.weights] \n",
    "                           for _ts in t])\n",
    "\n",
    "        if self.bias is not None:\n",
    "            return np.array([[layer + bias.item() for layer, bias in zip(_ts, self.bias)] for _ts in result])\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "\n",
    "def convolute1d(ts, filter_matrix, stride):\n",
    "    x_d = len(ts)\n",
    "    x_f = len(filter_matrix)\n",
    "\n",
    "    x_stride = stride[0]\n",
    "\n",
    "    x_o = ((x_d - x_f) // x_stride) + 1\n",
    "\n",
    "    def get_submatrix(matrix, x):\n",
    "        index_column = x * x_stride\n",
    "        return matrix[index_column: index_column + x_f]\n",
    "\n",
    "    return np.array(\n",
    "        [np.sum(get_submatrix(ts, x) * filter_matrix) for x in range(0, x_o)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14 20 26 32 38 44 50]\n"
     ]
    }
   ],
   "source": [
    "ts = np.array( [1, 2, 3, 4, 5, 6, 7, 8, 9] )\n",
    "filter_matrix = np.array( [1, 2, 3] )\n",
    "print(convolute1d(ts, filter_matrix, [1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PINPOINT_2CONV(\n",
       "  (main): Sequential(\n",
       "    (0): Conv1d(1, 16, kernel_size=(5,), stride=(1,))\n",
       "    (1): Square()\n",
       "    (2): Conv1d(16, 32, kernel_size=(3,), stride=(1,))\n",
       "    (3): Square()\n",
       "    (4): Flatten(start_dim=1, end_dim=-1)\n",
       "    (5): Linear(in_features=192, out_features=96, bias=True)\n",
       "    (6): Linear(in_features=96, out_features=48, bias=True)\n",
       "    (7): Linear(in_features=48, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_c1 = model.main[0].cpu()\n",
    "torch_c2 = model.main[2].cpu()\n",
    "c1 = ConvolutionalLayer(torch_c1.weight.detach().numpy(), torch_c1.stride, torch_c1.padding, torch_c1.bias)\n",
    "c2 = ConvolutionalLayer(torch_c2.weight.detach().numpy(), torch_c2.stride, torch_c2.padding, torch_c2.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = _train.values.reshape(len(_train), 1)\n",
    "\n",
    "inputs_normalized = scaler.transform(inputs)\n",
    "inputs_normalized = torch.FloatTensor(inputs_normalized[-seq_length:]).to(device)\n",
    "inputs_normalized = inputs_normalized.reshape(1, 1, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = inputs_normalized.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_out_1 = torch_c1(inputs_normalized.cpu())\n",
    "torch_out_2 = torch_c2(torch_out_1)\n",
    "\n",
    "pycrcnn_out_1 = c1(inp)\n",
    "pycrcnn_out_2 = c2(pycrcnn_out_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.32948136, -0.13188641, -0.10636571, -0.0558827 , -0.07941146,\n",
       "       -0.09219632], dtype=float32)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pycrcnn_out_2[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3295, -0.1319, -0.1064, -0.0559, -0.0794, -0.0922],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_out_2[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 8])\n",
      "(1, 16, 8)\n"
     ]
    }
   ],
   "source": [
    "print(torch_out_1.shape)\n",
    "print(pycrcnn_out_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 6])\n",
      "(1, 32, 6)\n"
     ]
    }
   ],
   "source": [
    "print(torch_out_2.shape)\n",
    "print(pycrcnn_out_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(torch_out_1.detach().numpy(), pycrcnn_out_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(torch_out_2.detach().numpy(), pycrcnn_out_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-2.9802322e-08,  1.4901161e-08,  4.4703484e-08,  0.0000000e+00,\n",
       "          7.4505806e-09,  2.9802322e-08],\n",
       "        [-5.9604645e-08, -2.9802322e-08,  2.9802322e-08,  0.0000000e+00,\n",
       "          0.0000000e+00, -1.4901161e-08],\n",
       "        [ 7.4505806e-08,  0.0000000e+00,  0.0000000e+00, -2.9802322e-08,\n",
       "         -2.9802322e-08,  1.4901161e-08],\n",
       "        [ 5.9604645e-08, -2.9802322e-08,  0.0000000e+00,  0.0000000e+00,\n",
       "         -2.9802322e-08, -1.8626451e-08],\n",
       "        [ 0.0000000e+00,  2.9802322e-08, -8.9406967e-08,  4.4703484e-08,\n",
       "          0.0000000e+00, -5.9604645e-08],\n",
       "        [-2.9802322e-08,  1.8626451e-08,  1.4901161e-08, -7.4505806e-09,\n",
       "          7.4505806e-09, -1.4901161e-08],\n",
       "        [ 0.0000000e+00,  2.9802322e-08, -2.9802322e-08,  0.0000000e+00,\n",
       "          2.9802322e-08, -1.4901161e-08],\n",
       "        [ 1.1920929e-07,  1.1920929e-07,  0.0000000e+00,  5.9604645e-08,\n",
       "          0.0000000e+00, -5.9604645e-08],\n",
       "        [-4.4703484e-08,  1.4901161e-08,  2.9802322e-08, -2.9802322e-08,\n",
       "         -1.4901161e-08,  0.0000000e+00],\n",
       "        [-7.4505806e-09, -4.4703484e-08, -1.4901161e-08,  4.4703484e-08,\n",
       "          9.6857548e-08,  4.0978193e-08],\n",
       "        [ 0.0000000e+00,  5.9604645e-08,  5.9604645e-08,  2.9802322e-08,\n",
       "          0.0000000e+00, -2.9802322e-08],\n",
       "        [ 5.9604645e-08, -5.9604645e-08, -5.9604645e-08,  0.0000000e+00,\n",
       "         -5.9604645e-08,  2.9802322e-08],\n",
       "        [ 5.9604645e-08,  5.9604645e-08,  0.0000000e+00,  5.9604645e-08,\n",
       "          0.0000000e+00,  2.9802322e-08],\n",
       "        [ 2.2351742e-08,  2.9802322e-08,  4.4703484e-08,  4.4703484e-08,\n",
       "          7.4505806e-09, -1.4901161e-08],\n",
       "        [-5.9604645e-08,  1.7881393e-07,  5.9604645e-08,  5.9604645e-08,\n",
       "          1.1920929e-07,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  5.9604645e-08,  5.9604645e-08,  0.0000000e+00,\n",
       "          2.9802322e-08,  1.1920929e-07],\n",
       "        [ 2.9802322e-08,  0.0000000e+00, -2.9802322e-08, -2.9802322e-08,\n",
       "         -5.9604645e-08, -8.9406967e-08],\n",
       "        [ 2.9802322e-08, -2.9802322e-08,  1.4901161e-08, -2.9802322e-08,\n",
       "         -2.9802322e-08,  1.4901161e-08],\n",
       "        [ 8.9406967e-08,  6.7055225e-08,  5.2154064e-08, -4.4703484e-08,\n",
       "          0.0000000e+00,  0.0000000e+00],\n",
       "        [-5.9604645e-08,  5.9604645e-08,  0.0000000e+00,  0.0000000e+00,\n",
       "          0.0000000e+00,  0.0000000e+00],\n",
       "        [-3.3527613e-08,  1.4901161e-08, -1.4901161e-08,  0.0000000e+00,\n",
       "          0.0000000e+00,  0.0000000e+00],\n",
       "        [ 2.9802322e-08,  0.0000000e+00, -5.9604645e-08, -4.4703484e-08,\n",
       "         -1.4901161e-08, -2.6077032e-08],\n",
       "        [ 1.4901161e-08,  2.9802322e-08, -2.9802322e-08,  1.1175871e-08,\n",
       "          5.5879354e-09,  1.4901161e-08],\n",
       "        [ 0.0000000e+00,  3.7252903e-08,  2.9802322e-08,  1.4901161e-08,\n",
       "          2.9802322e-08,  7.4505806e-09],\n",
       "        [-1.1920929e-07,  1.4901161e-07,  0.0000000e+00,  0.0000000e+00,\n",
       "         -5.9604645e-08, -1.4901161e-08],\n",
       "        [-1.4901161e-07, -8.9406967e-08, -2.9802322e-08,  0.0000000e+00,\n",
       "          0.0000000e+00,  1.4901161e-08],\n",
       "        [-1.7881393e-07,  0.0000000e+00,  0.0000000e+00, -2.9802322e-08,\n",
       "         -2.9802322e-08,  5.9604645e-08],\n",
       "        [ 0.0000000e+00,  5.9604645e-08,  0.0000000e+00,  0.0000000e+00,\n",
       "         -2.9802322e-08, -1.4901161e-08],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  2.9802322e-08,\n",
       "          2.9802322e-08, -7.4505806e-09],\n",
       "        [ 0.0000000e+00,  1.1920929e-07,  0.0000000e+00,  1.1920929e-07,\n",
       "          0.0000000e+00,  0.0000000e+00],\n",
       "        [ 2.9802322e-08,  0.0000000e+00, -5.9604645e-08,  2.9802322e-08,\n",
       "          0.0000000e+00,  0.0000000e+00],\n",
       "        [-5.9604645e-08,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "          0.0000000e+00,  0.0000000e+00]]], dtype=float32)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_out_2.detach().numpy() - pycrcnn_out_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-3.29481363e-01, -1.31886408e-01, -1.06365710e-01,\n",
       "         -5.58826961e-02, -7.94114619e-02, -9.21963155e-02],\n",
       "        [-2.43459761e-01, -3.51462454e-01, -4.29031104e-01,\n",
       "         -3.42738330e-01, -2.42686629e-01, -1.65710464e-01],\n",
       "        [ 1.37510374e-01,  2.10252553e-01,  2.79890716e-01,\n",
       "          2.91717201e-01,  2.30780423e-01,  2.07163870e-01],\n",
       "        [-3.07030082e-01, -3.85308117e-01, -3.32821250e-01,\n",
       "         -2.69986808e-01, -1.55314639e-01, -4.56414111e-02],\n",
       "        [ 1.81319341e-01,  2.34996319e-01,  2.41125494e-01,\n",
       "          1.85159400e-01,  1.19449630e-01,  9.38674212e-02],\n",
       "        [-1.49477601e-01, -2.71312036e-02, -4.92407046e-02,\n",
       "         -4.06488366e-02, -2.71976143e-02, -1.08691305e-01],\n",
       "        [-2.52759367e-01, -3.25511247e-01, -3.85629773e-01,\n",
       "         -2.96744049e-01, -1.78671360e-01, -1.37597203e-01],\n",
       "        [ 7.36791074e-01,  8.58288705e-01,  8.84172738e-01,\n",
       "          8.51966918e-01,  7.39866555e-01,  5.94550312e-01],\n",
       "        [ 1.03070833e-01,  1.94614500e-01,  3.02712291e-01,\n",
       "          2.95684487e-01,  2.46221662e-01,  1.43964961e-01],\n",
       "        [-9.60412398e-02, -1.01541974e-01, -6.05687499e-02,\n",
       "         -2.40549222e-02,  5.49283624e-03, -5.41889146e-02],\n",
       "        [ 2.74901867e-01,  2.93160737e-01,  2.33078271e-01,\n",
       "          2.95877486e-01,  3.00547123e-01,  3.93937647e-01],\n",
       "        [ 4.62758690e-01,  4.64233726e-01,  4.59595591e-01,\n",
       "          4.01639611e-01,  3.40255767e-01,  2.25649327e-01],\n",
       "        [ 4.64157462e-01,  3.88967216e-01,  2.89351642e-01,\n",
       "          2.50563085e-01,  1.67016014e-01,  2.36594245e-01],\n",
       "        [ 8.13662633e-02,  6.14702404e-02, -2.39431113e-02,\n",
       "         -7.82310963e-05,  1.10358007e-01,  1.52851894e-01],\n",
       "        [ 5.42853713e-01,  7.65830100e-01,  8.41183484e-01,\n",
       "          7.54280984e-01,  6.18855834e-01,  4.47084844e-01],\n",
       "        [-6.77897751e-01, -6.26712143e-01, -5.18124521e-01,\n",
       "         -4.12071377e-01, -3.09568018e-01, -2.44857907e-01],\n",
       "        [-2.08421022e-01, -2.93872982e-01, -2.89214790e-01,\n",
       "         -3.32642972e-01, -3.27142984e-01, -2.30022401e-01],\n",
       "        [ 4.57311332e-01,  4.05387729e-01,  2.44931951e-01,\n",
       "          1.82444081e-01,  2.24866897e-01,  1.34580523e-01],\n",
       "        [-9.13359672e-02,  1.64720416e-03,  3.78789976e-02,\n",
       "         -2.78358310e-02, -1.87204674e-01, -2.40733281e-01],\n",
       "        [-4.29876089e-01, -6.95361733e-01, -8.21295679e-01,\n",
       "         -6.85686588e-01, -5.20968616e-01, -3.47774655e-01],\n",
       "        [ 6.08283803e-02,  1.56879067e-01,  1.26341656e-01,\n",
       "          1.03060625e-01,  3.23296860e-02, -3.56340036e-02],\n",
       "        [ 3.07820827e-01,  3.51980925e-01,  2.54305780e-01,\n",
       "          1.99532747e-01,  1.74179912e-01,  4.77961749e-02],\n",
       "        [ 8.02193061e-02,  1.02133922e-01,  6.65166453e-02,\n",
       "         -4.53062542e-03, -2.65970435e-02, -4.82579544e-02],\n",
       "        [ 2.20047504e-01,  1.64518133e-02, -1.37835145e-01,\n",
       "         -1.82567328e-01, -8.57974738e-02, -4.11993675e-02],\n",
       "        [ 8.12544525e-02, -5.91013283e-02, -2.31479287e-01,\n",
       "         -2.79709339e-01, -1.07769318e-01, -6.27150759e-02],\n",
       "        [-2.52393514e-01, -3.99504155e-01, -4.17078644e-01,\n",
       "         -3.14438045e-01, -1.71168178e-01, -1.12015560e-01],\n",
       "        [-5.27875066e-01, -4.66166675e-01, -4.33687150e-01,\n",
       "         -3.38349581e-01, -3.02556753e-01, -2.16016531e-01],\n",
       "        [-5.70178270e-01, -6.94511414e-01, -5.54232478e-01,\n",
       "         -4.40684825e-01, -1.10347807e-01,  7.52692968e-02],\n",
       "        [-2.60546029e-01, -3.16512853e-01, -3.23688447e-01,\n",
       "         -2.79092848e-01, -2.37130225e-01, -8.16050395e-02],\n",
       "        [ 8.12047482e-01,  7.57686138e-01,  7.67492294e-01,\n",
       "          8.01121116e-01,  7.66252995e-01,  7.31204748e-01],\n",
       "        [ 2.73778886e-01,  1.92670554e-01,  1.86598182e-01,\n",
       "          1.99226618e-01,  2.30476946e-01,  1.81565076e-01],\n",
       "        [ 4.40758884e-01,  4.86441255e-01,  4.70544875e-01,\n",
       "          4.08003449e-01,  2.85717398e-01,  2.82720029e-01]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pycrcnn_out_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 12)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_inp = np.array([ [ [ 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0 ] ] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 9)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Conv1d(in_channels=1, out_channels=2, kernel_size=3, bias=False)\n",
    "\n",
    "conv1.weight = nn.Parameter(torch.Tensor(sample_weight_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2 = nn.Conv1d(in_channels=2, out_channels=3, kernel_size=3, bias=False)\n",
    "\n",
    "conv2.weight = nn.Parameter(torch.Tensor(sample_weight_c2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weight_1 = np.array([ [ [ 1.0, 2.0, 3.0 ] ] , [[ 2.0, 3.0, 4.0 ]] ])\n",
    "sample_c1 = ConvolutionalLayer(sample_weight_1, conv1.stride, conv1.padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weight_c2 = np.array([ [ [ 1.0, 2.0, 3.0 ], [2.0, 3.0, 4.0] ], \n",
    "                              [ [ 5.0, 6.0, 7.0 ], [8.0, 9.0, 10.0] ], \n",
    "                              [ [ 11.0, 12.0, 13.0 ], [14.0, 15.0, 16.0] ] ])\n",
    "sample_c2 = ConvolutionalLayer(sample_weight_c2, conv2.stride, conv1.padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = conv1(torch.Tensor(sample_inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[14., 20., 26., 32., 38., 44., 50.],\n",
       "         [20., 29., 38., 47., 56., 65., 74.]]], grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 411.,  528.,  645.,  762.,  879.],\n",
       "         [1173., 1524., 1875., 2226., 2577.],\n",
       "         [2055., 2676., 3297., 3918., 4539.]]], grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = sample_c1(sample_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[14., 20., 26., 32., 38., 44., 50.],\n",
       "        [20., 29., 38., 47., 56., 65., 74.]]])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 411.,  528.,  645.,  762.,  879.],\n",
       "        [1173., 1524., 1875., 2226., 2577.],\n",
       "        [2055., 2676., 3297., 3918., 4539.]]])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_c2(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLayer:\n",
    "    def __init__(self, weights, bias=None):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "        if bias is not None:\n",
    "            self.bias = bias\n",
    "\n",
    "    def __call__(self, t):\n",
    "        result = np.array([[np.sum(ts * row) for row in self.weights] for ts in t])\n",
    "        if self.bias is not None:\n",
    "            result = np.array([row + self.bias for row in result])\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin1 = model.main[5].cpu()\n",
    "lin2 = model.main[6].cpu()\n",
    "lin3 = model.main[7].cpu()\n",
    "\n",
    "pycrcnn_lin1 = LinearLayer(lin1.weight.detach().numpy(), lin1.bias.detach().numpy())\n",
    "pycrcnn_lin2 = LinearLayer(lin2.weight.detach().numpy(), lin2.bias.detach().numpy())\n",
    "pycrcnn_lin3 = LinearLayer(lin3.weight.detach().numpy(), lin3.bias.detach().numpy())\n",
    "# c1 = ConvolutionalLayer(torch_c1.weight.detach().numpy(), torch_c1.stride, torch_c1.padding, torch_c1.bias)\n",
    "# c2 = ConvolutionalLayer(torch_c2.weight.detach().numpy(), torch_c2.stride, torch_c2.padding, torch_c2.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = np.ones(192).reshape(1, 192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = lin1(torch.Tensor(inp))\n",
    "out2 = lin2(out1)\n",
    "out3 = lin3(out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.4264, -1.6281, -2.2950, -1.8667, -1.8219, -2.1086]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "pycrcnn_out1 = pycrcnn_lin1(inp)\n",
    "pycrcnn_out2 = pycrcnn_lin2(pycrcnn_out1)\n",
    "pycrcnn_out3 = pycrcnn_lin3(pycrcnn_out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.42642315, -1.62807017, -2.29497676, -1.86671326, -1.82189733,\n",
       "        -2.10862728]])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pycrcnn_out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copia di TS_Exercises2_Planned.ipynb",
   "provenance": [
    {
     "file_id": "1W1_DAqrdw9AQrIWwZLPsGMRA8xDBAjKM",
     "timestamp": 1636703056169
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "PINPOINT",
   "language": "python",
   "name": "pinpoint"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
